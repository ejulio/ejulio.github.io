<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aprendizado De Máquina on Júlio César Batista</title><link>https://juliocesarbatista.com/tags/aprendizado-de-m%C3%A1quina/</link><description>Recent content in Aprendizado De Máquina on Júlio César Batista</description><generator>Hugo</generator><language>pt-br</language><lastBuildDate>Tue, 09 Jul 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://juliocesarbatista.com/tags/aprendizado-de-m%C3%A1quina/index.xml" rel="self" type="application/rss+xml"/><item><title>Experimentos com Machine Learning</title><link>https://juliocesarbatista.com/posts/experimentos-ml/</link><pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/experimentos-ml/</guid><description>O problema que machine learning visa resolver é encontrar a melhor função de decisão dado um conjunto de dados. Portanto, este problem contém um conjunto de entrada $\mathcal{X}$, um algoritmo de aprendizado $\mathcal{A}$ e, normalmente, um conjunto de saídas esperadas $\mathcal{y}$. Assim, como é possível saber se a função de decisão $\mathcal{f}$ gerada por $\mathcal{A}$ é realmente útil? A resposta é que é necessário avaliar um experimento sobre o desempenho (performance) de $\mathcal{f}$ em um conjunto de dados.</description></item><item><title>Como funcionam as redes neurais</title><link>https://juliocesarbatista.com/posts/como-funcionam-as-redes-neurais/</link><pubDate>Thu, 30 Nov 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/como-funcionam-as-redes-neurais/</guid><description>Olá, tudo bem!?
Amanhã, 30 de novembro, eu vou apresentar a palestra &amp;ldquo;Como funcionam as rdes neurais&amp;rdquo; no GDG Blumenau aqui em Blumenau, Santa Catarina. Os slides e exemplo da palestra estão disponíveis aqui.
Aparece por lá para conferir e trocar uma ideia :D</description></item><item><title>A normalização e o Gradient Descent</title><link>https://juliocesarbatista.com/posts/a-normalizacao-e-o-gradient-descent/</link><pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/a-normalizacao-e-o-gradient-descent/</guid><description>Vamos falar sobre machine learning. Estou [enfim] participando do MOOC do Andrew Ng, Ph. D. no Coursera e me deparei com a importância de normalizar os dados antes de efetuar a otimização do algoritmo de aprendizado. Não leve a mal, sei, há certo tempo, que é importante normalizar os valores de entrada para que o algoritmo tenha uma melhor, e mais rápida, convergência. Entretanto, nunca havia, ao menos até onde percebi, me deparado com o quanto esse pré-processamento implica no processo.</description></item><item><title>Conheça o machine learning: algoritmos que aprendem a partir de dados, imagens e texto</title><link>https://juliocesarbatista.com/posts/conheca_o_machine_learning/</link><pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/conheca_o_machine_learning/</guid><description>Olá, tudo bem!?
Amanhã, 14 de agosto, eu vou apresentar a palestra &amp;ldquo;Conheça o machine learning: algoritmos que aprendem a partir de dados, imagens e texto&amp;rdquo; na XXI Semana de Informática da UNIFAI em Adamantina, São Paulo. Os slides da palestra podem ser visualizados aqui.
Espero que você goste!</description></item><item><title>Desmistificando o Deep Learning com TensorFlow</title><link>https://juliocesarbatista.com/posts/desmistificando-o-deep-learning-com-tensorflow/</link><pubDate>Wed, 03 May 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/desmistificando-o-deep-learning-com-tensorflow/</guid><description>Olá, tudo bem!?
Eu e o Vítor Albiero vamos falar sobre deep learning na The Developers Conference (TDC) Florianópolis 2017 na trilha de Data Science e Machine Learning. A palestra se chama &amp;ldquo;Desmistificando o Deep Learning com TesnsorFlow&amp;rdquo; e também vai estar na trilha stadium da Intel e vai ser transmitida gratuitamente pela internet.
Nesses links você pode acessar os slides da talk e também os códigos.
Espero que você goste!</description></item><item><title>Cross-validation: testando o desempenho de um classificador</title><link>https://juliocesarbatista.com/posts/cross-validation-testando-o-desempenho-de-um-classificador/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/cross-validation-testando-o-desempenho-de-um-classificador/</guid><description>Olá pessoal, tudo certo!?
Hoje vamos falar sobre aprendizado de máquina. Não vamos falar sobre as técnicas de classificação, mas sobre as técnicas de verificação de desempenho dos algoritmos.
Dados e características Link para o cabeçalho O exemplo de teste será a classificação de texto baseado no tutorial de classificação de texto do scikit-learn. O código inicial é:
Entre as linhas 12 e 15 definimos os dados que serão usados para o teste de classificação.</description></item></channel></rss>