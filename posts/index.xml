<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Júlio César Batista</title><link>https://juliocesarbatista.com/posts/</link><description>Recent content in Posts on Júlio César Batista</description><generator>Hugo -- gohugo.io</generator><language>pt-br</language><lastBuildDate>Tue, 31 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://juliocesarbatista.com/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>How to reduce noise in the data through data parsing</title><link>https://juliocesarbatista.com/posts/how-to-reduce-noise-in-the-data-through-data-parsing/</link><pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/how-to-reduce-noise-in-the-data-through-data-parsing/</guid><description>No blog da Zyte https://www.zyte.com/blog/how-to-reduce-noise-in-the-data-through-data-parsing/</description></item><item><title>Scrapy Cloud secrets: Hub Crawl Frontier and how to use it</title><link>https://juliocesarbatista.com/posts/scrapy-cloud-secrets-hub-crawl-frontier-and-how-to-use-it/</link><pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/scrapy-cloud-secrets-hub-crawl-frontier-and-how-to-use-it/</guid><description>No blog da Zyte https://www.zyte.com/blog/scrapy-cloud-secrets-hub-crawl-frontier-and-how-to-use-it/</description></item><item><title>Custom crawling &amp; News API: designing a web scraping solution</title><link>https://juliocesarbatista.com/posts/extract-articles-at-scale-designing-a-web-scraping-solution/</link><pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/extract-articles-at-scale-designing-a-web-scraping-solution/</guid><description>No blog da Zyte https://www.zyte.com/blog/extract-articles-at-scale-designing-a-web-scraping-solution/</description></item><item><title>Provas matemáticas diretas</title><link>https://juliocesarbatista.com/posts/provas-matematicas-diretas/</link><pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/provas-matematicas-diretas/</guid><description>Na matemática, provas de argumentos são obtidas a partir de um processo de raciocínio lógico. Por mais criativo que possa ser esse processo, existem algumas &amp;ldquo;fórmulas&amp;rdquo; que podem ajudar no caminho. O primeiro passo é formular o argumento que requer uma prova. Isso é possível ao escrever uma proposição (afirmação) que só pode ter dois resultados possíveis: verdadeiro ou falso, nunca os dois juntos. Assim, é possível construir uma argumentação para chegar na conclusão se determinada proposição é verdadeira ou não.</description></item><item><title>Correção ortográfica com índice k-gram</title><link>https://juliocesarbatista.com/posts/correcao-ortografica-k-gram-index/</link><pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/correcao-ortografica-k-gram-index/</guid><description>Ao escrever uma consulta, o usuário pode cometer erros ortográficos durante a digitação. Esses erros podem ter duas formas: escrita incorreta da palavra (comesso ao invés de começo), contexto (no meu casa ao invés de na minha casa). Note que no primeiro exemplo, a palavra está incorreta; no segundo, as palavras estão corretas mas o contexto é errado. Nesse momento, a ideia é ver como é possível fazer a correção de erros de escrito (primeiro caso).</description></item><item><title>Executando consultas por frases: Positional Index</title><link>https://juliocesarbatista.com/posts/phrase-queries-positional-index/</link><pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/phrase-queries-positional-index/</guid><description>Para realizar a consulta por frases (sequências de palavras) é necessário um índice k-gram. Porém, criar um índice todas as combinações de termos pode ocupar muito espaço em disco/memória. Principalmente se for necessário indexar combinações de 5 ou mais palavras, visto que muitas combinações podem aparecer apenas uma ou outra vez. Uma solução para esse problema é um positional index (índice de posições).
Em um índice invertido, termos são mapeados para listas com ids de documentos.</description></item><item><title>Compressão de índices: Variable Byte Encoding</title><link>https://juliocesarbatista.com/posts/compressao-indices-vbe/</link><pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/compressao-indices-vbe/</guid><description>Uma vez que o índice invertido está montado com postings lists, é necessário persistí-lo em disco. O detalhe é que, se o índice for persistido como texto em UTF-8, cada caractére vai requisitar ao menos 8 bytes. Portando, o id 4568912 requer 7 bytes para ser armazenado. A contrapartida é que, se for armazenado como um numérico (int por exemplo), precisa de apenas 4 bytes. Porém, é possível conseguir uma melhora na compressão ao considerar a estrutura de dados que será armazenada.</description></item><item><title>Executando consultas por frases</title><link>https://juliocesarbatista.com/posts/phrase-queries/</link><pubDate>Fri, 03 Jan 2020 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/phrase-queries/</guid><description>A partir de um índice de termos/documentos só é possível efetuar consultas de ocorrência de termos e filtros com operadores AND, OR e NOT. Entretanto, o que é preciso para executar uma consulta por presidente do Brasil? A forma mais simples, é converter essa consulta em presidente AND do AND Brasil (o do pode ser removido se quiser remover stop words). O detalhe é que essa consulta vai retornar qualquer documento que contenha presidente e Brasil, mas que não não fale necessariamento do presidente do Brasil.</description></item><item><title>Algoritmos para consultar em índices</title><link>https://juliocesarbatista.com/posts/algoritmos-indices/</link><pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/algoritmos-indices/</guid><description>Uma das vantagens do índice invertido é a possibilidade de otimizar os algoritmos utilizados nas consultas. Esses algoritmos já são implementados por set no python, mas não garantem a sequência dos ids dos documentos e também não permitem algumas otimizações. Portanto, é necessário passar por esses algoritmos para ver as extensões e como elas podem ajudar.
intersecção de conjuntos Uma consulta casa AND blumenau precisa efetuar a intersecção entre os documentos de casa e os documentos de blumenau.</description></item><item><title>Considerações sobre a construção de índices</title><link>https://juliocesarbatista.com/posts/consideracoes-sobre-indices/</link><pubDate>Mon, 30 Dec 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/consideracoes-sobre-indices/</guid><description>Para construir um índice, seja uma matriz de incidência ou um índice invertido, alguns detalhes em relação aos documentos e aos termos do vocabulário devem ser considerados.
Documentos O primeiro ponto a se considerar é o que será indexado, o que será um documento no índice. Um livro pode ser considerado um documento, o problema é que existem muitas palavras em um livro e diferentes palavras podem ocorrer em capítulos diferentes gerando um resultado não esperado.</description></item><item><title>Índice invertido (inverted index)</title><link>https://juliocesarbatista.com/posts/indice-invertido/</link><pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/indice-invertido/</guid><description>A matriz de incidência termo-documento é uma das formas de representar um índice de termos por documento. Mesmo usando o conceito de uma matriz esparsa, essa estrutura pode crescer muito para ser usada em memória. Uma alternativa para esse caso é usar um índice invertido (inverted index).
Dados os seguintes documentos como exemplo:
Uma casa à venda em Blumenau Vendo terreno em Gaspar Alugo apartamento em Indaial A matriz de incidência é:</description></item><item><title>Matriz de incidência termo-documento</title><link>https://juliocesarbatista.com/posts/matriz-incidencia-termo-documento/</link><pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/matriz-incidencia-termo-documento/</guid><description>Para obter as ocorrências de uma query booleana, por exemplo, casa AND blumenau seria necessário passar em todos os documentos procurando por casa e depois procurar novamente por blumenau. De certa forma, essa abordagem não é completamente ruim. Mas existem algumas abordagens que podem melhorar o tempo da consulta e consumo de memória.
Agora considere uma nova consulta, por exemplo, casa AND gaspar, seria necessário repassar em todos os documentos novamente.</description></item><item><title>Soma dos números pares na sequência Fibonacci</title><link>https://juliocesarbatista.com/posts/soma-pares-fibonacci/</link><pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/soma-pares-fibonacci/</guid><description>Os números de Fibonacci (Wikipedia, Wikipedia) são uma sequência definida como $F_n = F_{n-2} + F_{n-1}$. Os primeiros números são 0 e 1, e a partir deles, a sequência segue: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, &amp;hellip;. Dada a definição da sequência Fibonacci, como se calcula a soma dos números pares até $F_n &amp;lt; C$?
A solução simples é fazer um script conforme
C = 100 F_n2 = 0 F_n1 = 1 soma = 0 while True: F_n = F_n2 + F_n1 if F_n &amp;gt;= C: break elif F_n % 2 == 0: soma += F_n F_n2 = F_n1 F_n1 = F_n print(soma) Mas é possível fazer melhor?</description></item><item><title>Experimentos com Machine Learning</title><link>https://juliocesarbatista.com/posts/experimentos-ml/</link><pubDate>Tue, 09 Jul 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/experimentos-ml/</guid><description>O problema que machine learning visa resolver é encontrar a melhor função de decisão dado um conjunto de dados. Portanto, este problem contém um conjunto de entrada $\mathcal{X}$, um algoritmo de aprendizado $\mathcal{A}$ e, normalmente, um conjunto de saídas esperadas $\mathcal{y}$. Assim, como é possível saber se a função de decisão $\mathcal{f}$ gerada por $\mathcal{A}$ é realmente útil? A resposta é que é necessário avaliar um experimento sobre o desempenho (performance) de $\mathcal{f}$ em um conjunto de dados.</description></item><item><title>Técnicas de combinatória</title><link>https://juliocesarbatista.com/posts/combinatoria/</link><pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/combinatoria/</guid><description>Dado um conjunto $S$ qualquer com $n$ elementos, de quantas formas é possível organizar/ordenar os elementos? Quantos subconjuntos de $S$ com $k &amp;lt;= n$ elementos podem ser criados? Essas respostas podem ser encontradas com algumas técnicas de combinatória.
Definições $ S = \text{ { A, B, C, D } } $ e $n = \lvert S \rvert = 4$
De quantas formas é possível organizar/ordenar os elementos?</description></item><item><title>Votes, scores e ranks</title><link>https://juliocesarbatista.com/posts/votes-scores-ranks/</link><pubDate>Fri, 10 May 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/votes-scores-ranks/</guid><description>Votes, scores e ranks são, normalmente, utilizados em conjunto. Por exemplo, scores são funções utilizadas para reduzir dados multi-dimensionais para uma única dimensão. Com base nesse score, é possível ordenar os dados através de um rank. Assim, é possível acessar o n-ésimo elemento a partir de um rank. Votes, é um dos exemplos que pode ser reduzido a partir de uma função score.
Um exemplo comum é o ranking de produtos em uma página baseado na avaliação dos usuários.</description></item><item><title>Limpando dados (data cleaning)</title><link>https://juliocesarbatista.com/posts/data-cleaning/</link><pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/data-cleaning/</guid><description>A limpeza dos dados é um passo importante na construção de uma análise e modelo. Entretanto, não existe um fluxo exato para seguir, a ideia é explorar o dataset e identificar registros inválidos e aplicar regras para corrigí-los. A seguir tem uma lista do que procurar/corrigir em datasets.
1. Conversão de tipos Simples, se o valor deve ser um numérico e está como string, então usa-se o tipo mais apropriado.</description></item><item><title>Python: conjuntos (sets)</title><link>https://juliocesarbatista.com/posts/python-sets/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/python-sets/</guid><description>Vamos falar um pouco sobre sets (conjuntos) em python. Se você já trabalha com a linguagem, provavelmente já se deparou com esses casos, mas se está iniciando na linguagem, talvez sejam exemplos interessantes para aprender.
Por que conjuntos? Conjuntos são coleções que não permitem elementos duplicados. Dessa forma, são uma ótima estrutura de dados para verificar se um elemento já existe e garantir que esse elemento exista apenas uma vez.</description></item><item><title>Regressão múltipla com redes neurais convolucionais para estimativa conjunta da intensidade de Action Units</title><link>https://juliocesarbatista.com/posts/wtd-2017/</link><pubDate>Tue, 30 Oct 2018 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/wtd-2017/</guid><description>Abstract: Este trabalho apresenta uma rede neural convolucional (CNN - Convolutional Neural Network) para efetuar a estimativa conjunta da intensidade de Action Units (AUs) em imagens de faces. A estimativa da intensidade de AUs é essencial durante a análise de expressões faciais. Os métodos existentes não levam em consideração a possibilidade de estimativa conjunta para vários AUs em uma face e precisam de um modelo para cada AU; métodos que fazem uso dessa informação precisam reestruturar o problema como aprendizado estruturado com grafos, aumentando a complexidade.</description></item><item><title>Matemágica para devs</title><link>https://juliocesarbatista.com/posts/matemagica-para-devs/</link><pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/matemagica-para-devs/</guid><description>Oi, tudo certo!?
Nos dias 28/07/2018 e 11/08/2018 eu apresentei duas palestras sobre matemática com foco em conceitos úteis para desenvolvedores de software. O conteúdo está disponível no GitHub. De forma geral, vimos:
Conceitos fundamentais da álgebra; Distribuições e os conceitos de média, moda, mediana e desvio padrão na estatística; Matrizes, vetores e norms na álgebra linear; Funções, derivadas e otimização com cálculo. A ideia era aproximar esses conceitos com Python e bibliotecas que facilitam essas operações.</description></item><item><title>Sobre métodos ágeis</title><link>https://juliocesarbatista.com/posts/sobre-metodos-ageis/</link><pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/sobre-metodos-ageis/</guid><description>Vamos falar sobre metodologias ágeis, principalmente em um SAAS (Software as a Service). Para começar, não sou um expert em metodologias ágeis, assim como não passei por todos os possíveis casos que eles podem envolver. Portanto, posso ter uma visão enviesada para os conceitos que acredito fazer mais sentido. Depois desse disclaimer, vamos lá!
Não me leve a mal, eu acho que Scrum (e outras metodologias baseadas em sprint) é uma metodologia fantástica, só não acredito que ele seja o melhor processo para uma empresa que trabalha com um SAAS.</description></item><item><title>Processamento de imagens com python</title><link>https://juliocesarbatista.com/posts/processamento-imagens-python-grupy/</link><pubDate>Sat, 20 Jan 2018 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/processamento-imagens-python-grupy/</guid><description>Olá, tudo bem!?
Na última semana de janeiro, ainda não tem data definida, vou falar sobre processamento de imagens com python e scikit-image no Grupy Blumenau. O notebook com o conteúdo da apresentação já está disponível no GitHub.
Aparece por lá para conferir e trocar uma ideia :D</description></item><item><title>Objectives and Key-Results (OKRs)</title><link>https://juliocesarbatista.com/posts/okrs/</link><pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/okrs/</guid><description>Vamos falar sobre desenvolvimento de software.
Objectives and Key-Results (OKRs) são uma prática/framework/metodologia para definir objetivos, os Objectives, e definir resultados que indiquem o quão próximos estamos desses objetivos, os Key-Results. Essa prática não é um framework ágil como o Scrum/XP/Kanban, mas sim uma forma de alinhar os objetivos da empresa com todos os indivíduos e como cada um pode contribuir nesses objetivos. Com isso, é possível colocar o template padrão de OKRs:</description></item><item><title>Como funcionam as redes neurais</title><link>https://juliocesarbatista.com/posts/como-funcionam-as-redes-neurais/</link><pubDate>Thu, 30 Nov 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/como-funcionam-as-redes-neurais/</guid><description>Olá, tudo bem!?
Amanhã, 30 de novembro, eu vou apresentar a palestra &amp;ldquo;Como funcionam as rdes neurais&amp;rdquo; no GDG Blumenau aqui em Blumenau, Santa Catarina. Os slides e exemplo da palestra estão disponíveis aqui.
Aparece por lá para conferir e trocar uma ideia :D</description></item><item><title>Face Analysis in the Wild</title><link>https://juliocesarbatista.com/posts/face-analysis-in-the-wild/</link><pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/face-analysis-in-the-wild/</guid><description>Abstract: With the global demand for extra security systems, and the growing of human-machine interaction, facial analysis in unconstrained environments (in the wild) became a hot-topic in recent computer vision research. Unconstrained environments include surveillance footage, social media photos and live broadcasts. This type of images and videos include no control over illumination, position, size, occlusion, and facial expressions. Successful facial processing methods for controlled scenarios are unable to pledge with challenging circumstances.</description></item><item><title>A normalização e o Gradient Descent</title><link>https://juliocesarbatista.com/posts/a-normalizacao-e-o-gradient-descent/</link><pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/a-normalizacao-e-o-gradient-descent/</guid><description>Vamos falar sobre machine learning. Estou [enfim] participando do MOOC do Andrew Ng, Ph. D. no Coursera e me deparei com a importância de normalizar os dados antes de efetuar a otimização do algoritmo de aprendizado. Não leve a mal, sei, há certo tempo, que é importante normalizar os valores de entrada para que o algoritmo tenha uma melhor, e mais rápida, convergência. Entretanto, nunca havia, ao menos até onde percebi, me deparado com o quanto esse pré-processamento implica no processo.</description></item><item><title>Conheça o machine learning: algoritmos que aprendem a partir de dados, imagens e texto</title><link>https://juliocesarbatista.com/posts/conheca_o_machine_learning/</link><pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/conheca_o_machine_learning/</guid><description>Olá, tudo bem!?
Amanhã, 14 de agosto, eu vou apresentar a palestra &amp;ldquo;Conheça o machine learning: algoritmos que aprendem a partir de dados, imagens e texto&amp;rdquo; na XXI Semana de Informática da UNIFAI em Adamantina, São Paulo. Os slides da palestra podem ser visualizados aqui.
Espero que você goste!</description></item><item><title>AUMPNet: Simultaneous Action Units Detection and Intensity Estimation on Multipose Facial Images Using a Single Convolutional Neural Network</title><link>https://juliocesarbatista.com/posts/aumpnet/</link><pubDate>Sat, 03 Jun 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/aumpnet/</guid><description>Abstract: This paper presents an unified convolutional neural network (CNN), named AUMPNet, to perform both Action Units (AUs) detection and intensity estimation on facial images with multiple poses. Although there are a variety of methods in the literature designed for facial expression analysis, only few of them can handle head pose variations. Therefore, it is essential to develop new models to work on non-frontal face images, for instance, those obtained from unconstrained environments.</description></item><item><title>Desmistificando o Deep Learning com TensorFlow</title><link>https://juliocesarbatista.com/posts/desmistificando-o-deep-learning-com-tensorflow/</link><pubDate>Wed, 03 May 2017 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/desmistificando-o-deep-learning-com-tensorflow/</guid><description>Olá, tudo bem!?
Eu e o Vítor Albiero vamos falar sobre deep learning na The Developers Conference (TDC) Florianópolis 2017 na trilha de Data Science e Machine Learning. A palestra se chama &amp;ldquo;Desmistificando o Deep Learning com TesnsorFlow&amp;rdquo; e também vai estar na trilha stadium da Intel e vai ser transmitida gratuitamente pela internet.
Nesses links você pode acessar os slides da talk e também os códigos.
Espero que você goste!</description></item><item><title>Landmark-free smile intensity estimation</title><link>https://juliocesarbatista.com/posts/landmark-free-smile-intensity-estimation/</link><pubDate>Fri, 01 Jul 2016 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/landmark-free-smile-intensity-estimation/</guid><description>Abstract: Facial expression analysis is an important field of research, mostly because of the rich information faces can provide. The majority of works published in the literature have focused on facial expression recognition and so far estimating facial expression intensities have not gathered same attention. The analysis of these intensities could improve face processing applications on distinct areas, such as computer assisted health care, human-computer interaction and biometrics. Because the smile is the most common expression, studying its intensity is a first step towards estimating other expressions intensities.</description></item><item><title>Batman é você? Desenhando o símbolo do Batman com retas, parábolas e círculos</title><link>https://juliocesarbatista.com/posts/batman-e-voce-desenhando-o-simbolo-do-batman-com-retas-parabolas-e-circulos/</link><pubDate>Wed, 08 Jun 2016 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/batman-e-voce-desenhando-o-simbolo-do-batman-com-retas-parabolas-e-circulos/</guid><description>Olá, tudo certo!?
Hoje vamos trabalhar com a ideia de desenhar o símbolo do Batman com equações. Veremos alguns conceitos matemáticos que permitem fazer esse desenho. O desenho que eu vou demonstrar é um que fiz e talvez não seja com as melhores fórmulas nem a forma otimizada, mas acho que ele é bom um passo a passo sobre alguns conceitos da álgebra. O desenho é composto por retas, parábolas e círculos.</description></item><item><title>Cross-validation: testando o desempenho de um classificador</title><link>https://juliocesarbatista.com/posts/cross-validation-testando-o-desempenho-de-um-classificador/</link><pubDate>Fri, 27 May 2016 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/cross-validation-testando-o-desempenho-de-um-classificador/</guid><description>Olá pessoal, tudo certo!?
Hoje vamos falar sobre aprendizado de máquina. Não vamos falar sobre as técnicas de classificação, mas sobre as técnicas de verificação de desempenho dos algoritmos.
Dados e características O exemplo de teste será a classificação de texto baseado no tutorial de classificação de texto do scikit-learn. O código inicial é:
Entre as linhas 12 e 15 definimos os dados que serão usados para o teste de classificação.</description></item><item><title>The Dolly Zoom Effect</title><link>https://juliocesarbatista.com/posts/the-dolly-zoom-effect/</link><pubDate>Thu, 27 Aug 2015 00:00:00 +0000</pubDate><guid>https://juliocesarbatista.com/posts/the-dolly-zoom-effect/</guid><description>A ideia No post de hoje eu gostaria de demonstrar como fazer o efeito 3D dolly zoom effect utilizando a three.js.
Antes de irmos para a parte do código, eu vou deixar o link do vídeo onde eu vi o efeito. O vídeo também fala de outros efeitos e eu vou deixar marcado em dois pontos importantes para explicar o efeito posteriormente. O código [no Github] Inicialmente nós temos que fazer o setup da cena como no código abaixo.</description></item></channel></rss>