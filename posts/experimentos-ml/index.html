<!doctype html><html lang=pt-br><head><title>Experimentos com Machine Learning · Júlio César Batista
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Júlio César Batista"><meta name=description content="O problema que machine learning visa resolver é encontrar a melhor função de decisão dado um conjunto de dados. Portanto, este problem contém um conjunto de entrada $\mathcal{X}$, um algoritmo de aprendizado $\mathcal{A}$ e, normalmente, um conjunto de saídas esperadas $\mathcal{y}$. Assim, como é possível saber se a função de decisão $\mathcal{f}$ gerada por $\mathcal{A}$ é realmente útil? A resposta é que é necessário avaliar um experimento sobre o desempenho (performance) de $\mathcal{f}$ em um conjunto de dados."><meta name=keywords content="blog,software,developer"><meta name=fediverse:creator content><meta name=twitter:card content="summary"><meta name=twitter:title content="Experimentos com Machine Learning"><meta name=twitter:description content="O problema que machine learning visa resolver é encontrar a melhor função de decisão dado um conjunto de dados. Portanto, este problem contém um conjunto de entrada $\mathcal{X}$, um algoritmo de aprendizado $\mathcal{A}$ e, normalmente, um conjunto de saídas esperadas $\mathcal{y}$. Assim, como é possível saber se a função de decisão $\mathcal{f}$ gerada por $\mathcal{A}$ é realmente útil? A resposta é que é necessário avaliar um experimento sobre o desempenho (performance) de $\mathcal{f}$ em um conjunto de dados."><meta property="og:url" content="https://juliocesarbatista.com/posts/experimentos-ml/"><meta property="og:site_name" content="Júlio César Batista"><meta property="og:title" content="Experimentos com Machine Learning"><meta property="og:description" content="O problema que machine learning visa resolver é encontrar a melhor função de decisão dado um conjunto de dados. Portanto, este problem contém um conjunto de entrada $\mathcal{X}$, um algoritmo de aprendizado $\mathcal{A}$ e, normalmente, um conjunto de saídas esperadas $\mathcal{y}$. Assim, como é possível saber se a função de decisão $\mathcal{f}$ gerada por $\mathcal{A}$ é realmente útil? A resposta é que é necessário avaliar um experimento sobre o desempenho (performance) de $\mathcal{f}$ em um conjunto de dados."><meta property="og:locale" content="pt_br"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-07-09T00:00:00+00:00"><meta property="article:modified_time" content="2019-07-09T00:00:00+00:00"><meta property="article:tag" content="Aprendizado De Máquina"><meta property="article:tag" content="Experimentos"><meta property="article:tag" content="Sample Bias"><meta property="article:tag" content="Covariate Shift"><meta property="article:tag" content="Concept Drift"><link rel=canonical href=https://juliocesarbatista.com/posts/experimentos-ml/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.07092c1350ffd254998dc43a44ae96e617d14af4df4602626878df89189c5e1a.css integrity="sha256-BwksE1D/0lSZjcQ6RK6W5hfRSvTfRgJiaHjfiRicXho=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://juliocesarbatista.com/>Júlio César Batista
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/tags/publica%c3%a7%c3%a3o/>Publicações</a></li><li class=navigation-item><a class=navigation-link href=/tags/projeto/>Projetos</a></li><li class=navigation-item><a class=navigation-link href=/tags/notas/>Notas</a></li><li class=navigation-item><a class=navigation-link href=/tags/>Tags</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://juliocesarbatista.com/posts/experimentos-ml/>Experimentos com Machine Learning</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2019-07-09T00:00:00Z>2019-07-09
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
3 minutos de leitura</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/aprendizado-de-m%C3%A1quina/>Aprendizado De Máquina</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/experimentos/>Experimentos</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/sample-bias/>Sample Bias</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/covariate-shift/>Covariate Shift</a>
</span><span class=separator>•</span>
<span class=tag><a href=/tags/concept-drift/>Concept Drift</a></span></div></div></header><div class=post-content><p>O problema que <em>machine learning</em> visa resolver é <em>encontrar a melhor função de decisão dado um conjunto de dados</em>.
Portanto, este problem contém um conjunto de entrada $\mathcal{X}$, um algoritmo de aprendizado $\mathcal{A}$ e, normalmente, um conjunto de saídas esperadas $\mathcal{y}$.
Assim, como é possível saber se a função de decisão $\mathcal{f}$ gerada por $\mathcal{A}$ é realmente útil?
A resposta é que é necessário avaliar um experimento sobre o desempenho (<em>performance</em>) de $\mathcal{f}$ em um conjunto de dados.
Se levar em consideração apenas os dados utilizados para gerar $\mathcal{f}$, muito provavelmente o desempenho será bom/ótimo.
Dessa forma é necessário encontrar um conjunto similar a $\mathcal{X}$ e $\mathcal{y}$ que possa ser usado para avaliação.
A forma mais simples de encontrar esse conjunto é separar uma parte de $\mathcal{X}$ e $\mathcal{y}$ para treino e outra para teste.
Existem algumas formas de fazer essa separação e cada uma varia de acordo com o problema, por exemplo:
<em>leave one out</em>, <em>k-fold cross validation</em>, <em>forward chain</em> (para séries temporais) e outros.
O objetivo aqui não é discorrer sobre a melhor forma de separar os dados para o experimento, mas é levantar alguns pontos que devem ser considerados ao separar os dados para treino e teste.
Alguns problemas que devem ser evitados:</p><ul><li><strong>Covariate shift</strong>: quando a entrada $\mathcal{X}$ muda entre o conjunto de treino e o conjunto de teste.<ul><li>Exemplo: utilizar imagens em ambiente controlado para treino, mas a avaliação é com imagens não controladas (<a href=https://cs.nyu.edu/~roweis/papers/invar-chapter.pdf class=external-link target=_blank rel=noopener>Preface</a>)</li></ul></li><li><strong>Concept Drift</strong>: quando o resultado $\mathcal{y}$ para uma entrada $\mathcal{X}$ muda com o passar do tempo.<ul><li>Exemplo: sazonalidade (interesses mudam conforme a época do ano).</li></ul></li><li><strong>Sample bias</strong>: a distribuição de treino e teste são diferentes.<ul><li>Exemplo: a amostra não representa a população (<a href=https://www.geckoboard.com/learn/data-literacy/statistical-fallacies/sampling-bias/ class=external-link target=_blank rel=noopener><em>sampling bias</em></a>, <a href=https://www.geckoboard.com/learn/data-literacy/statistical-fallacies/survivorship-bias/ class=external-link target=_blank rel=noopener><em>survivorship bias</em></a>)</li></ul></li></ul><p>Os problemas acima podem ocorrer ao bolar o experimento/separação dos conjuntos e podem ter muito impacto no resutado do modelo obtido.
O impacto pode ser tanto no sentido de rejeitar um modelo bom, assim como aceitar um modelo ruim.
Portanto, é sempre importante avaliar estas circunstâncias ao montar os conjuntos experimentais.
Outro ponto que é importante é que esses casos devem ser considerados antes de iniciar qualquer avaliação do modelo.
Caso contrário, é possível obter conhecimento de onde o modelo está falhando e fazer uma otimização especial para esses casos (o que não é correto).
De forma geral, sempre vale se perguntar se o que é feito na fase de treino do modelo vai ser válido na fase de teste/produção.
Se a resposta é afirmativa, então é possível proceder; se existe dúvida, é melhor não fazer para evitar um viés do modelo.</p><p>Além dos pontos acima também é importante garantir que não exista <em>leakage</em> em $\mathcal{X}$ para $\mathcal{y}$.
Por exemplo, utilizar a pontuação (<em>rating</em>) de uma avaliação junto com o texto para prever o sentimento (bom/ruim) da avaliação.
Nesse caso, o modelo pode simplesmente ignorar o texto e usar a pontuação, visto que uma pontuação baixa indica uma revisão (sentimento) ruim.</p><p>Referências:</p><ul><li><a href=https://davidrosenberg.github.io/mlcourse/Archive/2017Fall/Lectures/01.black-box-ML.pdf class=external-link target=_blank rel=noopener><em>Black Box Machine Learning</em></a></li></ul></div><footer></footer></article><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})'></script></section></div><footer class=footer><section class=container>©
2016 -
2024
Júlio César Batista
·
Promovido por <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-1BE56W9H8M"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-1BE56W9H8M")}</script></body></html>